# 프롬프트 엔지니어링
- ❓ 프롬프트 엔지니어링이란 : 효과적으로 작업을 전달하여 정확하고 유용한 출력을 반환하도록 유도하는 llm에 대한 압력을 만드는 것.

## 언어 모델에서의 정렬
언어모델이 어떻게 사람의 입력에 정렬되는지 이해 필요.

- ❓ 언어 모델에서의 정렬 이란 : 모델이 사용자가 예상한것과 일치하는 방식으로 입력 프롬프트를 이해하고 답변하는것을 말합니다.

(예시) 프롬프트 엔지니어링 향상을 위해 몇몇 언어모델은 추가적인 정렬 기능과 함께 개발
- 엔트로픽 : AI 피드백 기반 강화 학습 (RLAIF)
- 오픈AI : 인간 피드백 기반 강화 학습 (RLHF)
RLAIF, RLHF들은 명확한 지시사항과 피드백을 모델의 훈련에 통합할수 있습니다. 이러한 정렬 기술은 특정 프롬프트를 이해하고 답변하는 모델의 능력을 향상시켜 질문-답변이나 언어 번역과 같은 애플리케이션을 더 유용하게 만들 수 있습니다.

<img width="639" height="472" alt="image" src="https://github.com/user-attachments/assets/25a3c9f1-2484-46a3-b40a-3680d727aeb4" />

## 직접 요청하기
- 요청하는 내용이 최대한 명확하고 직접적이어야 한다. (단순할수록 좋다)
```
이문장의 문법을 수정하세요.
They went to the store and buy food

-> (LLM답변) They went to the store to buy food
```

## 퓨샷 학습
작업에 대한 깊은 이해가 필요한 복잡한 작업의 경우, 몇가지 예제를 LLM에 제공하면 정확하고 일관된 출력을 생성하는데 큰 도움이 될수 있습니다.

### 퓨샷학습
- LLM에 작업의 몇가지 예제를 제공하여 문제의 맥락과 애매한 차이를 이해하는 데 도움을 주는 강력한 기술

<img width="956" height="722" alt="image" src="https://github.com/user-attachments/assets/754cce0b-6d6d-48ac-965a-9e5c05eef781" />


## 출력 형식 지정
- LLM은 다양한 형식으로 텍스트를 생성할 수 있지만, 때론 너무 지나칠수 있다. 이런 상황에서 출력 형식을 지정하는 것은 다른 시스템과 통합하고 작업하기 쉽게 하는데 도움이 된다.
```
영어를 튀르키예어로 번역해주세요.
최종결과는 유효한 json 형식으로 만들어주세요.
English : How do I call a cab from the airport?

(LLM 답변)
{
  "english": "How do I call a cab from the airport?",
  "turkish": "Havalimanından nasıl taksi çağırabilirim?",
  "pronunciation": "하발리마는단 나슬 탁시 차으라빌리림?"
}
```

## 페르소나 정하기
```
(페르소나 없음)
Q: 당근이 어디 있나요?
A: 당근은 상품코너의 양파와 감자 근처에 있습니다.

(건방진 페르소나)
Q: 당근이 어디 있나요?
A: 저기

(재밌는 페르소나)
Q: 당근이 어디 있나요?
A: 이쪽입니다. 저를 따라오시면 당근이 어디 있는지 보여드릴게요. 여기 있네요. 이제 집어가시기만 하면 됩니다.

(반 채식주의자 페르소나)
Q: 당근이 어디 있나요?
A: 당근을 왜 원하죠? 당근은 역겹고 맛이 없잖아요. 여기선 스테이크와 베이컨 같은 좋은것만 팔아요. 한번 고기를 먹어보는건 어때요?
```

페르소나는 항상 긍정적인 목적으로 사용되지는 않는다. 다른 도구나 기술과 마찬가지로 (반채식주의자의 행동을 모방하도록 요청한것처럼) 일부 사람들은 LLM을 사용하여 유행한 메시지를 생성하기도 한다.
LLM의 개발자들은 이러한 잠재적인 오용을 완화하기 위한 조치로써, 콘텐츠 필터를 구현하고 관리자와 협력하여 모델의 출력을 검토하는 등의 작업을 수행한다.

## 연쇄적 사고 프롬프트

COT(Chain Of Thought) 프롬프트는 LLM에 일련의 단계를 통해 추론하도록 하여 보다 구조화되고 투명하며 정확한 출력을 생성하는 방법.
더 작고 상호연결된 하위 작업으로 세분화하여 LLM이 각 하위 작업을 단계별로 처리하도록 하는 것.

COT 장점
- LLM이 생성한 답변의 해석 가능성과 투명성이 향상!



